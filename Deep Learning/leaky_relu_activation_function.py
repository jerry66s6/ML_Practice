# -*- coding: utf-8 -*-
"""Leaky ReLU Activation Function

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/123Cu3AiEXBXwwC2Yi_1G8lUqeCWUl3AO
"""

def leaky_relu(z: float, alpha: float = 0.01) -> float|int:
	# Your code here
    if z>= 0:
		return z
	else:
		if alpha is not None:
			return z*alpha
		else:
			return z*0.01