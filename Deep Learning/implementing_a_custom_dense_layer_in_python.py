# -*- coding: utf-8 -*-
"""Implementing a Custom Dense Layer in Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/123Cu3AiEXBXwwC2Yi_1G8lUqeCWUl3AO
"""

import numpy as np
import copy
import math

# DO NOT CHANGE SEED
np.random.seed(42)

# DO NOT CHANGE LAYER CLASS
class Layer(object):

	def set_input_shape(self, shape):

		self.input_shape = shape

	def layer_name(self):
		return self.__class__.__name__

	def parameters(self):
		return 0

	def forward_pass(self, X, training):
		raise NotImplementedError()

	def backward_pass(self, accum_grad):
		raise NotImplementedError()

	def output_shape(self):
		raise NotImplementedError()

# Your task is to implement the Dense class based on the above structure
class Dense(Layer):
	def __init__(self, n_units, input_shape=None):
		self.layer_input = None
		self.input_shape = input_shape
		self.n_units = n_units
		self.trainable = True
		self.W = None
		self.w0 = None

	def initialize(self, optimizer):
		limit = 1/math.sqrt(self.input_shape[0])
		self.W = np.random.uniform(-limit, limit, (self.input_shape[0], self.n_units))
		self.w0 = np.zeros((1, self.n_units))
		self.W_opt = copy.copy(optimizer)
		self.w0_opt = copy.copy(optimizer)

	def forward_pass(self, X, training=True):
		self.layer_input = X
		output = np.dot(X, self.W)+self.w0
		return output

	def backward_pass(self, accum_grad):
		W = self.W
		if self.trainable ==True:
			dw = np.dot(self.layer_input.T, accum_grad)
			grad = np.sum(accum_grad, axis=0, keepdims=True)
			self.W = self.W_opt.update(self.W, dw)
			self.w0 = self.w0_opt.update(self.w0, grad)
		dldx = np.dot(accum_grad, W.T)
		return dldx

	def output_shape(self):
		return (self.n_units,)

	def number_of_parameters():
		return (self.W.shape[0]*self.W.shape[1]+self.w0.shape[1])