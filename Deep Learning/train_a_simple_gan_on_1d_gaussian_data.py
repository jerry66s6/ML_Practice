# -*- coding: utf-8 -*-
"""Train a Simple GAN on 1D Gaussian Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ddSTk9mzwXrGGcc23dWtWNcJd2Z_g0b
"""

import numpy as np

def train_gan(mean_real: float, std_real: float, latent_dim: int = 1, hidden_dim: int = 16, learning_rate: float = 0.001, epochs: int = 5000, batch_size: int = 128, seed: int = 42):
    """
    Train a simple GAN to learn a 1D Gaussian distribution.

    Args:
        mean_real: Mean of the target Gaussian
        std_real: Std of the target Gaussian
        latent_dim: Dimension of the noise input to the generator
        hidden_dim: Hidden layer size for both networks
        learning_rate: Learning rate for gradient descent
        epochs: Number of training epochs
        batch_size: Training batch size
        seed: Random seed for reproducibility

    Returns:
        gen_forward: A function that takes z and returns generated samples
    """
    # Your code here
    rng = np.random.default_rng(seed)
    def relu(x):
        return np.maximum(0.0, x)
    def relu_grad(x):
        return (x>0.0).astype(x.dtype)
    def sigmoid(x):
        return 1.0/(1.0+np.exp(-x))

    #Generator
    wstd = 0.01
    Wg1 = rng.normal(0.0, wstd, size = (latent_dim, hidden_dim))
    bg1 = np.zeros((hidden_dim,), dtype = float)
    Wg2 = rng.normal(0.0, wstd, size = (hidden_dim, 1))
    bg2 = np.zeros((1,), dtype = float)
    #Discriminator
    Wd1 = rng.normal(0.0, wstd, size = (1, hidden_dim))
    bd1 = np.zeros((hidden_dim,), dtype = float)
    Wd2 = rng.normal(0.0, wstd, size = (hidden_dim, 1))
    bd2 = np.zeros((1,), dtype = float)

    def G_forward(z):
        h1_pre = z @ Wg1+bg1
        h1 = relu(h1_pre)
        x = h1 @ Wg2 + bg2
        cache = (z, h1_pre, h1)
        return x, cache

    def D_forward(x):
        h1_pre = x @ Wd1+bd1
        h1 = relu(h1_pre)
        logits = h1 @ Wd2 +bd2
        p = sigmoid(logits)
        cache = (x, h1_pre, h1, logits, p)
        return p, cache

    #back
    def D_backward(dlogits, cache):
        x, h1_pre, h1, logits, p = cache
        dWd2 = h1.T @ dlogits
        dbd2 = np.sum(dlogits, axis= 0)
        dh1 = dlogits @ Wd2.T

        dh1_pre = dh1*relu_grad(h1_pre)
        dWd1 = x.T @ dh1_pre
        dbd1 = np.sum(dh1_pre, axis = 0)
        dx = dh1_pre @ Wd1.T
        return dx, (dWd1, dbd1, dWd2, dbd2)

    def G_backward(dx, cache):
        z, h1_pre, h1 = cache
        dWg2 = h1.T @ dx
        dbg2 = np.sum(dx, axis = 0)
        dh1 = dx @ Wg2.T

        dh1_pre = dh1 @ relu_grad(h1_pre)
        dWg1 = z.T @ dh1_pre
        dbg1 = np.sum(dh1_pre, axis = 0)
        return (dWg1, dbg1, dWg2, dbg2)
    lr = learning_rate
    B = batch_size
    for _ in range(epochs):
        x_real = rng.normal(mean_real, std_real, size = (B, 1))
        z = rng.normal(0.0, 1.0, size = (B, latent_dim))
        x_fake, _ = G_forward(z)

        p_real, cache_real = D_forward(x_real)
        p_fake, cache_fake = D_forward(x_fake)

        dlogits_real = (p_real -1.0)/B
        dlogits_fake = (p_fake-0.0)/B

        _, (dWd1_r, dbd1_r, dWd2_r, dbd2_r) =  D_backward(dlogits_real, cache_real)
        _, (dWd1_f, dbd1_f, dWd2_f, dbd2_f) =  D_backward(dlogits_fake, cache_fake)

        Wd1 -= lr*(dWd1_r+dWd1_f)
        bd1 -= lr*(dWb1_r+dWb1_f)
        Wd2 -= lr*(dWd2_r+dWd2_f)
        bd2 -= lr*(dWb2_r+dWb2_f)

        z = rng.normal(0.0, 1.0, size = (B, latent_dim))
        x_fake, cache_g = G_forward(z)
        p_fake, cache_df = D_forward(x_fake)
        dlogits_g = (p_fake-1.0)/B
        dx_fake, _ = D_backward(dlogits_g,cache_df)
        dWg1, dbg1, dWg2, dbg2 = G_backward(dx_fake, cache_g)

        Wg1 -= lr * dWg1
        bg1 -= lr * dbg1
        Wg2 -= lr * dWg2
        bg2 -= lr * dbg2
    def gen_forward(z):
        z = np.asarray(z, dtype=float)
        if z.ndim ==1:
            z = z.reshape(-1, latent_dim)
        x, _ = G_forward(z)
        return x, None, None
    return gen_forward